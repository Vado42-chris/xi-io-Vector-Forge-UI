#!/bin/bash
# Setup Local AI for Free Coding
# This sets up Ollama so you can code without using remote API credits

echo "ğŸš€ Setting up Local AI for Free Coding..."
echo ""

# Step 1: Check if Ollama is installed
echo "Step 1: Checking Ollama installation..."
if command -v ollama > /dev/null; then
    echo "âœ… Ollama is installed: $(which ollama)"
    OLLAMA_VERSION=$(ollama --version 2>/dev/null || echo "unknown")
    echo "   Version: $OLLAMA_VERSION"
else
    echo "âŒ Ollama not found. Installing..."
    curl -fsSL https://ollama.com/install.sh | sh
    if [ $? -eq 0 ]; then
        echo "âœ… Ollama installed successfully"
    else
        echo "âŒ Installation failed. Please install manually:"
        echo "   curl -fsSL https://ollama.com/install.sh | sh"
        exit 1
    fi
fi
echo ""

# Step 2: Check if Ollama is running
echo "Step 2: Checking if Ollama is running..."
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama is running on http://localhost:11434"
else
    echo "âš ï¸  Ollama not running. Starting..."
    ollama serve > /dev/null 2>&1 &
    sleep 3
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama started successfully"
    else
        echo "âŒ Failed to start Ollama. Please start manually:"
        echo "   ollama serve"
        exit 1
    fi
fi
echo ""

# Step 3: Check available models
echo "Step 3: Checking available models..."
MODELS=$(curl -s http://localhost:11434/api/tags 2>/dev/null | grep -o '"name":"[^"]*"' | cut -d'"' -f4 || echo "")
if [ -z "$MODELS" ]; then
    echo "âš ï¸  No models found. Installing codellama:latest (good for coding)..."
    echo "   This may take a few minutes..."
    ollama pull codellama:latest
    if [ $? -eq 0 ]; then
        echo "âœ… Model installed successfully"
    else
        echo "âŒ Model installation failed"
        exit 1
    fi
else
    echo "âœ… Models available:"
    echo "$MODELS" | sed 's/^/   - /'
    # Check if codellama is available
    if echo "$MODELS" | grep -q "codellama"; then
        echo "âœ… codellama found (good for coding)"
    else
        echo "âš ï¸  codellama not found. Installing..."
        ollama pull codellama:latest
    fi
fi
echo ""

# Step 4: Verify setup
echo "Step 4: Verifying setup..."
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama API is accessible"
    echo "âœ… Setup complete!"
    echo ""
    echo "ğŸ“‹ Next Steps:"
    echo "1. Start VectorForge: npm run dev"
    echo "2. Open VectorForge â†’ Left Sidebar â†’ Engine tab"
    echo "3. Enable 'Use Local GGUF Models'"
    echo "4. Select Ollama â†’ http://localhost:11434"
    echo "5. Click Refresh â†’ Select codellama:latest"
    echo "6. Click Test â†’ Save"
    echo ""
    echo "ğŸ‰ You're now coding for FREE with local AI!"
else
    echo "âŒ Setup verification failed"
    exit 1
fi

